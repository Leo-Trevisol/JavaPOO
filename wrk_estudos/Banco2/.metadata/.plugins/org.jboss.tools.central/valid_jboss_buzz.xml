<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title type="html">Exceptional rules, with Drools and Kogito</title><link rel="alternate" href="https://blog.kie.org/2023/01/exceptional-rules-with-drools-and-kogito.html" /><author><name>Matteo Mortari</name></author><id>https://blog.kie.org/2023/01/exceptional-rules-with-drools-and-kogito.html</id><updated>2023-01-14T12:18:01Z</updated><content type="html">Managing exceptional rules is easy, thanks to Drools and Kogito! In this use-case, we have a base business process and a default knowledge base with rules, which can be overridden by specific entities or departments as needed. We actually have several architectural options we could implement! The simplest architectural option I can think about, draws inspiration from this book by Alan Fish: “Knowledge Automation: How to Implement Decision Management in Business Processes” Book by Alan N. Fish which is a great book by the way if you also want to understand the main ideas prequel to the DMN standard! Exceptional rules using only DMN In a decision node in DMN, we check if any exception is applicable, and we collect the exceptions in a list. * If the exception list is empty, we apply the default knowledge and rules. * Otherwise, we apply the rules related to the most relevant exceptions from the list. You may substitute the BKM nodes with Decision Service, say coming from other DMN models! Another option is to model this with a combination of BPMN and DMN and rules, the idea is similar: Managing exceptional rules with BPMN and DMN The default branch applies the default knowledge base and would be followed, unless in the predetermination task we have evaluated we must follow one of the exceptional types of branches. A final option would be to deploy each knowledge base –the default one, the different exceptional ones– each as its own Kogito microservice on a cloud native environment such as Kubernetes: Then, you can orchestrate them using a Serverless Workflow, which will be in charge of invoking the needed cloud-native decision service. As you have seen, managing exceptional rules is easy, thanks to Drools and Kogito! The post appeared first on .</content><dc:creator>Matteo Mortari</dc:creator></entry><entry><title type="html">How to Cache the Response with RestEasy</title><link rel="alternate" href="http://www.mastertheboss.com/jboss-frameworks/resteasy/how-to-cache-the-response-with-resteasy/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/jboss-frameworks/resteasy/how-to-cache-the-response-with-resteasy/</id><updated>2023-01-13T08:35:35Z</updated><content type="html">Resteasy is a popular Java framework for building RESTful web services. One of its features is the ability to cache HTTP responses using the @Cache and @NoCache annotations. Caching REST Response To use the @Cache annotation, you need to add it to a method that returns an HTTP response. The annotation takes a few parameters ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">Quarkus Newsletter #28 - January</title><link rel="alternate" href="https://quarkus.io/blog/quarkus-newsletter-28/" /><author><name>James Cobb</name></author><id>https://quarkus.io/blog/quarkus-newsletter-28/</id><updated>2023-01-13T00:00:00Z</updated><content type="html">A fresh new year is a perfect time for some fresh new articles in the Quarkus Newsletter. "Fine-grained authorization for Quarkus microservices" by Raffaele Spazzoli is a great article describing a solution we call fine-grained authorization and uses Quarkus to implement Relationship-Based Access Control (ReBAC) in the manner of Google...</content><dc:creator>James Cobb</dc:creator></entry><entry><title type="html">Solving “Could not find MessageBodyWriter for response object of type”</title><link rel="alternate" href="http://www.mastertheboss.com/jboss-frameworks/resteasy/solving-could-not-find-messagebodywriter-for-response-object-of-type/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/jboss-frameworks/resteasy/solving-could-not-find-messagebodywriter-for-response-object-of-type/</id><updated>2023-01-12T15:46:33Z</updated><content type="html">This article discusses the steps to solve the error “org.jboss.resteasy.core.NoMessageBodyWriterFoundFailure: Could not find MessageBodyWriter for response object of type” that you can have at runtime in a REST application. The Problem This error message is indicating that the RESTEasy framework (which is a JAX-RS implementation for Java) is unable to find a suitable “MessageBodyWriter” for ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">How to list Maven local artifacts using JBang</title><link rel="alternate" href="http://www.mastertheboss.com/java/how-to-list-maven-local-artifacts-using-jbang/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/java/how-to-list-maven-local-artifacts-using-jbang/</id><updated>2023-01-12T11:06:14Z</updated><content type="html">Listing the available artifacts in your Maven local repository generally requires a Maven project. In this article we will show how to create a simple JBang script to list all dependencies for an artifact in your local Maven repository. Firstly, install JBang in your environment: Then, if you are new to JBang, I’d recommend checking ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">How to wait in Java with Awaitility</title><link rel="alternate" href="http://www.mastertheboss.com/various-stuff/testing-java/testing-with-awaitility-made-simple/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/various-stuff/testing-java/testing-with-awaitility-made-simple/</id><updated>2023-01-12T10:48:19Z</updated><content type="html">The Awaitility library introduces a functional style usage to express expectations of an asynchronous system in a concise and easy to read manner. Let’s have a deep dive into it with this tutorial. Waiting in Java properly In order to make a pause during the execution of Java code you can use two main approaches: ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>How to autoscale your SaaS application infrastructure</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/01/12/how-autoscale-saas-application-infrastructure" /><author><name>Michael Hrivnak</name></author><id>3f2c7cc6-3830-4b59-978c-bb0d62a5ca5f</id><updated>2023-01-12T07:00:00Z</updated><published>2023-01-12T07:00:00Z</published><summary type="html">&lt;p&gt;This article discusses both how and why to scale your infrastructure automatically so that you aren't paying for resources you don't need. This is the last installment in the &lt;a href="https://developers.redhat.com/articles/2022/05/18/saas-architecture-checklist-kubernetes"&gt;SaaS architecture checklist series&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;If you are a Software-as-a-Service (SaaS) provider, it is important to manage operational expenses while ensuring that your platform's capacity can always meet the needs of your users. Whether the traffic to your SaaS peaks on a predictable schedule (for example, office hours on weekdays or seasonal shopping) or whether you are planning for growth, &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; has features to make sure you have the right level of capacity at any given time.&lt;/p&gt; &lt;p&gt;SaaS revenue typically comes through recurring fees that scale based on metrics such as the number of users, quantity of data stored or processed, access to advanced features, and other similar points of value. While each SaaS provider decides on their own pricing model and consumption metric, there is one common goal: The more your SaaS gets used, the more revenue you make.&lt;/p&gt; &lt;p&gt;But that usage also incurs increased infrastructure demand and expense. Maintaining a healthy operating income depends on keeping your infrastructure expenses below the corresponding revenue.&lt;/p&gt; &lt;p&gt;It pays to build on a compute platform that can scale in response to demand, with automation that scales the application in real-time. This article will discuss basic techniques for automatically scaling a Kubernetes cluster and an application based on load by combining three components:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Cluster API to enable cluster resizing&lt;/li&gt; &lt;li&gt;Cluster Autoscaler to resize the cluster based on load&lt;/li&gt; &lt;li&gt;Horizontal Pod Autoscaler to scale an application based on load&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Kubernetes native infrastructure&lt;/h2&gt; &lt;p&gt;Kubernetes native infrastructure is a pattern for using the Kubernetes API to manage some or all of the compute and network infrastructure used by a cluster. This concept is the foundation for some of the scalability components described in the following sections.&lt;/p&gt; &lt;p&gt;You can extend the Kubernetes API through &lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/"&gt;custom resources&lt;/a&gt;, which allow a software developer to add a new API endpoint to a cluster, write a controller to implement the features of that endpoint, and thus create a Kubernetes-native API to manage almost anything. You might have heard of the &lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator/"&gt;Operator Pattern&lt;/a&gt; that uses this technique of extending the Kubernetes API, typically for the purpose of managing applications, but custom resources can also be used to manage infrastructure.&lt;/p&gt; &lt;h2&gt;Cluster API&lt;/h2&gt; &lt;p&gt;The &lt;a href="https://cluster-api.sigs.k8s.io/"&gt;Cluster API project&lt;/a&gt; is a popular example of Kubernetes-native infrastructure management. One of its core capabilities is to add and remove nodes in an existing cluster using a concept called Machines. The API has a Machine API resource, which represents the desire to have a node in a cluster. The API also has a MachineSet API resource (similar in concept to a ReplicaSet), which includes a desired size and a template for creating Machines.&lt;/p&gt; &lt;p&gt;The Machine and MachineSet APIs let you resize a cluster just by changing an integer field to the number of nodes you desire. Figure 1 shows the API's basic behavior.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/Openshift%20cluster%20image.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/Openshift%20cluster%20image.png?itok=iqBIj8Bd" width="461" height="512" alt="The Machine API watches for changes and implements them using the platform-specific API." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: The Machine API watches for changes and implements them using the platform-specific API.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;At a very high level, cluster scaling using the cluster API project works like this:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;A person or automation decides to change the size of a MachineSet (more on this later).&lt;/li&gt; &lt;li&gt;A controller process either creates new Machine resources or deletes existing ones based on comparing the desired number of machines to the number that actually exists.&lt;/li&gt; &lt;li&gt;When a new Machine resource gets created, a platform-specific controller uses a cloud API to add a host to the cluster. For example, on AWS the controller would use the EC2 API to provision a new host.&lt;/li&gt; &lt;li&gt;When a Machine resource gets deleted, the platform-specific controller drains the corresponding node of workloads and then uses the platform-specific API to delete the host.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;With this simple approach, it's easy to scale a cluster up and down. The API works the same across different cloud providers, so scaling changes can be made without any cloud-specific knowledge.&lt;/p&gt; &lt;p&gt;But how can the scaling decision to add and remove nodes be automated based on the real-time load? That's the responsibility of the Cluster Autoscaler.&lt;/p&gt; &lt;h2&gt;Cluster Autoscaler&lt;/h2&gt; &lt;p&gt;The &lt;a href="https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler#cluster-autoscaler"&gt;Cluster Autoscaler&lt;/a&gt; uses the Machine API to add and remove nodes in a cluster based on its observations of workload scheduling pressure and node utilization. The Autoscaler adds nodes when pods cannot be scheduled due to resource constraints and removes underused nodes. Additional configuration is available, such as limits on how many nodes to create and settings that tune how aggressively the Autoscaler removes underused nodes.&lt;/p&gt; &lt;p&gt;Combining the Machine API with the Cluster Autoscaler, you can have a self-scaling compute platform that responds to the resource needs of your SaaS application.&lt;/p&gt; &lt;p&gt;To learn more about how &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt; enables machine management and scaling, including example resources, see the &lt;a href="https://docs.openshift.com/container-platform/4.11/machine_management/index.html"&gt;overview of machine management&lt;/a&gt; and the &lt;a href="https://docs.openshift.com/container-platform/4.11/machine_management/applying-autoscaling.html"&gt;autoscaler section&lt;/a&gt; of the product documentation.&lt;/p&gt; &lt;p&gt;But there is one more piece to the puzzle: How can you scale your application, adding and removing pods as its load changes over time? That is the job of the Horizontal Pod Autoscaler.&lt;/p&gt; &lt;h2&gt;Horizontal Pod Autoscaler&lt;/h2&gt; &lt;p&gt;&lt;a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"&gt;Horizontal Pod Autoscaling&lt;/a&gt; adds and removes pods in response to changing load. The service bases decisions on two metrics: CPU utilization and memory footprint. You can define thresholds at which pods will be added or removed to keep per-pod resource utilization near target values. In a common use case where a workload is defined as a &lt;a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/"&gt;Deployment&lt;/a&gt;, this Autoscaler adjusts the &lt;strong&gt;replicas&lt;/strong&gt; field based on load.&lt;/p&gt; &lt;p&gt;In the following example, a &lt;code&gt;frontend-app&lt;/code&gt; Deployment resource varies from 10 to 100 pods. Crucially, the Deployment's pod template must include a CPU &lt;a href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits"&gt;resource request&lt;/a&gt;. The Autoscaler uses each pod's actual CPU utilization to calculate a percentage of its CPU request and then uses the average to determine whether to scale the application up or down.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt; apiVersion: autoscaling/v1 kind: HorizontalPodAutoscaler metadata: name: frontend-app namespace: default spec: maxReplicas: 100 minReplicas: 10 scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: frontend-app targetCPUUtilizationPercentage: 75&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The newer &lt;a href="https://github.com/kubernetes/design-proposals-archive/blob/main/autoscaling/hpa-v2.md"&gt;autoscaling/v2 API&lt;/a&gt; lets you scale based on memory utilization and define more sophisticated policies. New policy options can configure how rapidly to make changes, including different policies that apply to scaling up versus scaling down. This API also supports the use of custom metrics.&lt;/p&gt; &lt;h2&gt;SaaS provisioning can be automated under Kubernetes&lt;/h2&gt; &lt;p&gt;Combining the Cluster API, Cluster Autoscaler, and Horizontal Pod Autoscaler, you can automatically scale your SaaS application up and down based on changes in utilization. The underlying infrastructure will automatically scale with your resource specifications, saving costs when utilization is low.&lt;/p&gt; &lt;p&gt;Red Hat SaaS Foundations is a partner program designed for building enterprise-grade SaaS solutions on the &lt;a href="https://developers.redhat.com/products/openshift/"&gt;Red Hat OpenShift&lt;/a&gt; or &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; platforms and deploying them across multiple cloud and non-cloud footprints. &lt;a href="http://mailto:saas@redhat.com"&gt;Email&lt;/a&gt; us to learn more about partnering with Red Hat to build your SaaS.&lt;/p&gt; &lt;p&gt;Be sure to read all the articles in the &lt;a href="https://developers.redhat.com/articles/2022/05/18/saas-architecture-checklist-kubernetes"&gt;SaaS architecture checklist series&lt;/a&gt;. Comment below if you have questions. We welcome your feedback. &lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/01/12/how-autoscale-saas-application-infrastructure" title="How to autoscale your SaaS application infrastructure"&gt;How to autoscale your SaaS application infrastructure&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Michael Hrivnak</dc:creator><dc:date>2023-01-12T07:00:00Z</dc:date></entry><entry><title type="html">Keycloak 20.0.3 released</title><link rel="alternate" href="https://www.keycloak.org/2023/01/keycloak-2003-released" /><author><name /></author><id>https://www.keycloak.org/2023/01/keycloak-2003-released</id><updated>2023-01-12T00:00:00Z</updated><content type="html">To download the release go to . MIGRATION FROM 19.0 Before you upgrade remember to backup your database. If you are not on the previous release refer to for a complete list of migration changes. ALL RESOLVED ISSUES BUGS * User role mapping tab: Show effective client roles for a user keycloak-ui section/users * ProviderConfigProperty.MAP_TYPE error in new UI keycloak-ui section/identity providers * Unable to turn on "Bypass identity confirmation" keycloak-ui section/authentication * Adding Form sub-flow broken on admin v2 keycloak-ui section/authentication * Custom User Provider SPI: There are no settings to configure the periodically synchronization of users keycloak-ui section/user federation * Assign roles to account - paging doesn't work keycloak-ui section/users * Realm selector requires two clicks to select something keycloak-ui section/realms * User management -&gt; User in 2 subgroups with the same group name assignment does not work keycloak-ui section/users * Invalid language tag error when changing realm localization settings keycloak-ui section/realm settings * `Missing ":type" param` in the Events page when there are Client Scope events keycloak-ui section/events * Import client broken keycloak-ui section/clients * New Admin Console only, unable to add client profile in the first client policy keycloak-ui section/realm settings * Disabling hostname strict in prod doesn't disable https keycloak dist/quarkus * snakeyaml vulnerability GHSA-3mc7-4q67-w48m impacting CLI keycloak admin/cli * The redirect URI cannot be verified during logout in the case when client was removed keycloak oidc * Wrong auth session id being used when validating auth session id cookies keycloak core * Update XStream to 1.4.20 to fix CVE-2022-40151 &amp;amp; CVE-2022-41966 keycloak * Timeout when executing command PutMapCommand keycloak storage * Set OkHttp to 4.10.0 in parent pom keycloak * Lack of validation of access token on client registrations endpoint keycloak oidc UPGRADING Before you upgrade remember to backup your database and check the for anything that may have changed.</content><dc:creator /></entry><entry><title type="html">JUnit 5 Cheatsheet (2023)</title><link rel="alternate" href="http://www.mastertheboss.com/various-stuff/testing-java/junit-5-cheatsheet/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/various-stuff/testing-java/junit-5-cheatsheet/</id><updated>2023-01-11T16:51:23Z</updated><content type="html">This article contains a JUnit 5 Cheatsheet which you can use as handy reference to build your JUnit 5 Jupiter Tests in Java. Maven Dependencies: Here is the list of dependencies you have to include in your pom.xml according to the latest JUnit version (): &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.junit.jupiter&lt;/groupId&gt; &lt;artifactId&gt;junit-jupiter-api&lt;/artifactId&gt; &lt;version&gt;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.junit.jupiter&lt;/groupId&gt; &lt;artifactId&gt;junit-jupiter-engine&lt;/artifactId&gt; ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">JUnit 5 Made Easy</title><link rel="alternate" href="http://www.mastertheboss.com/various-stuff/testing-java/getting-started-with-junit/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/various-stuff/testing-java/getting-started-with-junit/</id><updated>2023-01-11T16:09:45Z</updated><content type="html">JUnit 5 is a powerful testing framework for Java developers, allowing you to write and run repeatable, automated tests for your code. With its clear and expressive syntax, JUnit 5 makes it easy to write tests for a wide range of scenarios and use cases, from simple unit tests to complex integration tests. In this ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry></feed>
